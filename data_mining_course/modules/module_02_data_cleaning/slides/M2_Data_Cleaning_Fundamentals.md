# 模組二講義：資料清理的基礎 (Fundamentals of Data Cleaning)

---

## 1. 資料清理的「第一原理」 (First Principle)

> **Garbage In, Garbage Out (GIGO)**

這是整個資料科學領域最根本的「第一原理」之一。如果我們用有問題的、充滿「噪音」的資料來訓練模型或進行分析，那麼產出的結果也必然是不可靠的、甚至完全是錯誤的。

**資料清理 (Data Cleaning)** 的核心目的，就是系統性地處理 EDA 階段發現的資料品質問題，確保輸入到下一階段（特徵工程、模型建立）的資料是準確、一致且可靠的。

---

## 2. 資料清理的基礎 (Fundamentals)

本模組聚焦於資料清理中最常見、最基礎的四個任務。這些是進行任何嚴謹分析前的必備步驟。

### 2.1 處理記憶體限制：大檔案分塊處理

- **問題 (Problem)**: 當資料集的大小超過機器的 RAM 時，直接使用 `pd.read_csv()` 會導致 `MemoryError`。
- **解決方案 (Solution)**: 使用 `pd.read_csv()` 中的 `chunksize` 參數。
- **核心概念 (Core Concept)**: `chunksize` 會將讀取操作從「一次性載入」變為返回一個 **迭代器 (Iterator)**。你可以把這個迭代器想像成一條傳送帶，每次只傳送一「塊」(chunk) 資料給你處理，從而避免了記憶體耗盡。
- **常見模式 (Common Patterns)**:
  1.  **分塊計算**: 初始化變數 -> 遍歷所有 chunk -> 在迴圈中累計結果 -> 迴圈結束後計算最終值。
  2.  **分塊過濾**: 建立一個空列表 -> 遍歷所有 chunk -> 將每個 chunk 中符合條件的部分存入列表 -> 使用 `pd.concat()` 將所有小塊合併成最終的 DataFrame。

### 2.2 處理記錄錯誤：重複值 (Duplicates)

- **問題 (Problem)**: 重複的記錄會扭曲統計分析（如計數、平均值）、引入模型偏見，甚至在模型評估中造成嚴重的資料洩漏。
- **核心策略 (Core Strategy)**:
  - **識別**: 使用 `.duplicated()` 方法。它會返回一個布林遮罩 (boolean mask)，標示出哪些是重複行。
    - 預設情況下，除了第一次出現的，其餘都會被標為 `True`。
  - **移除**: 使用 `.drop_duplicates()` 方法。
- **關鍵參數 (Key Parameters)**:
  - `keep`: 控制保留哪一筆記錄。
    - `'first'` (預設): 保留第一筆。
    - `'last'`: 保留最後一筆。
    - `False`: 所有重複的記錄全部刪除。
  - `subset`: 指定一個欄位列表，僅基於這些欄位的組合來判斷是否重複。

### 2.3 處理格式錯誤：資料型態轉換 (Data Type Conversion)

- **問題 (Problem)**: 不正確的資料型態會導致計算錯誤、記憶體浪費、模型不相容和分析功能受限。
- **核心策略與工具 (Core Strategies & Tools)**:

| 轉換目標 | 推薦工具 | 關鍵點 / `errors` 參數 |
| :--- | :--- | :--- |
| **簡單轉換** | `.astype()` | 最直接的方法。例如: `.astype(int)`, `.astype(float)` |
| **有髒資料的數值** | `pd.to_numeric()` | **`errors='coerce'`** 是關鍵，它會將無法轉換的值變為 `NaN`，避免程式中斷。 |
| **日期/時間** | `pd.to_datetime()` | 轉換後會變成 `datetime64` 型態，解鎖 `.dt` 存取器，可以輕鬆提取年、月、日等特徵。 |
| **優化類別欄位** | `.astype('category')` | 對於唯一值數量有限的欄位 (如: '城市', '產品類別')，轉換為 `category` 型態能**大幅節省記憶體**。 |

### 2.4 處理非結構化資料：文字清理 (Text Cleaning)

- **問題 (Problem)**: 文字資料充滿噪音，如大小寫不一、多餘空白、標點符號，這些都會干擾後續的 NLP 分析。
- **核心策略 (Core Strategy)**: 使用 Pandas Series 的 **`.str` 存取器**，它可以將標準的 Python 字串方法應用到整個欄位的每一筆資料上。
- **基礎三步驟 (The Basic Trio)**:
  1.  **統一大小寫**: `.str.lower()` 或 `.str.upper()`。
  2.  **移除頭尾空白**: `.str.strip()`。
  3.  **移除標點符號**: `.str.replace(regex_pattern, '')`。通常會搭配 `string.punctuation` 和 `re.escape()` 來建立一個匹配所有標點的正則表達式。

---

## 3. 總結

資料清理是一個迭代且細緻的過程。雖然看起來是基礎操作，但每一步都直接關係到最終分析結果的品質與可信度。牢記 GIGO 的第一原理，並熟練運用本章節介紹的基礎工具，是成為一名可靠資料分析師的必經之路。 