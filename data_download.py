#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è³‡æ–™é›†ä¸‹è¼‰è…³æœ¬
ç”¨æ–¼ä¸‹è¼‰è³‡æ–™æ¢å‹˜èª²ç¨‹æ‰€éœ€çš„æ‰€æœ‰ Kaggle è³‡æ–™é›†
"""

import os
import subprocess
import time
import shutil
import sys
import zipfile

# ç¢ºä¿ Kaggle API æ†‘è­‰å­˜åœ¨
def check_kaggle_api():
    """æª¢æŸ¥ Kaggle API æ†‘è­‰æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å¼•å°ç”¨æˆ¶è¨­ç½®"""
    kaggle_dir = os.path.expanduser('~/.kaggle')
    kaggle_api_path = os.path.join(kaggle_dir, 'kaggle.json')
    
    if not os.path.exists(kaggle_api_path):
        print("æœªæ‰¾åˆ° Kaggle API æ†‘è­‰ã€‚")
        print("è«‹å‰å¾€ https://www.kaggle.com/account ç²å– API æ†‘è­‰")
        print("ä¸‹è¼‰ kaggle.json æª”æ¡ˆå¾Œï¼Œå°‡å…¶æ”¾ç½®æ–¼ ~/.kaggle/kaggle.json")
        
        # å˜—è©¦å‰µå»ºç›®éŒ„
        if not os.path.exists(kaggle_dir):
            os.makedirs(kaggle_dir)
        
        # æª¢æŸ¥ç•¶å‰ç›®éŒ„æ˜¯å¦æœ‰ kaggle.json
        if os.path.exists('kaggle.json'):
            print("åœ¨ç•¶å‰ç›®éŒ„æ‰¾åˆ° kaggle.jsonï¼Œæ­£åœ¨è¤‡è£½åˆ° ~/.kaggle/")
            shutil.copy('kaggle.json', kaggle_api_path)
            os.chmod(kaggle_api_path, 0o600)  # è¨­ç½®é©ç•¶çš„æ¬Šé™
            print(f"å·²è¤‡è£½ Kaggle API æ†‘è­‰æª”æ¡ˆåˆ°: {kaggle_api_path}")
        else:
            print("è«‹å°‡ kaggle.json æ”¾ç½®æ–¼ç•¶å‰ç›®éŒ„æˆ– ~/.kaggle/ ç›®éŒ„")
            sys.exit(1)
    
    # æª¢æŸ¥ kaggle å‘½ä»¤æ˜¯å¦å¯ç”¨
    try:
        subprocess.run(['kaggle', '--version'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    except (subprocess.SubprocessError, FileNotFoundError):
        print("æœªå®‰è£ Kaggle CLIã€‚æ­£åœ¨å˜—è©¦å®‰è£...")
        try:
            subprocess.run(['pip', 'install', 'kaggle'], check=True)
            print("Kaggle CLI å®‰è£æˆåŠŸï¼")
        except subprocess.SubprocessError:
            print("å®‰è£ Kaggle CLI å¤±æ•—ã€‚è«‹æ‰‹å‹•åŸ·è¡Œ: pip install kaggle")
            sys.exit(1)

# æª¢æŸ¥ä¸¦å®‰è£å¿…è¦çš„å¥—ä»¶
def check_and_install_packages():
    """æª¢æŸ¥ä¸¦å®‰è£å¿…è¦çš„å¥—ä»¶"""
    required_packages = ['kagglehub', 'requests', 'tqdm']
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ“ {package} å·²å®‰è£")
        except ImportError:
            print(f"æ­£åœ¨å®‰è£ {package}...")
            try:
                subprocess.run([sys.executable, '-m', 'pip', 'install', package], check=True)
                print(f"âœ“ {package} å®‰è£æˆåŠŸ")
            except subprocess.SubprocessError:
                print(f"Ã— {package} å®‰è£å¤±æ•—ï¼Œè«‹æ‰‹å‹•å®‰è£: pip install {package}")
                sys.exit(1)

# å®šç¾©è³‡æ–™é›†è³‡è¨Š
def get_datasets_info():
    """ç²å–æ‰€æœ‰éœ€è¦ä¸‹è¼‰çš„è³‡æ–™é›†è³‡è¨Š"""
    datasets = [
        {
            "module": "æ¨¡çµ„ä¸‰",
            "topic": "ç¼ºå¤±å€¼èˆ‡ç•°å¸¸å€¼è™•ç†",
            "name": "House Prices",
            "type": "competition",
            "method": "kaggle_cli",
            "competition_id": "house-prices-advanced-regression-techniques",
            "folder": "house_prices"
        },
        {
            "module": "æ¨¡çµ„å››",
            "topic": "é¡åˆ¥è®Šæ•¸ç·¨ç¢¼",
            "name": "Titanic",
            "type": "competition",
            "method": "kaggle_cli",
            "competition_id": "titanic",
            "folder": "titanic"
        },
        {
            "module": "æ¨¡çµ„äº”",
            "topic": "ç‰¹å¾µç¸®æ”¾èˆ‡è®Šæ•¸è½‰æ›",
            "name": "Medical Cost Personal Dataset",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "mirichoi0218/insurance",
            "folder": "insurance"
        },
        {
            "module": "æ¨¡çµ„å…­",
            "topic": "ç‰¹å¾µå‰µé€ ",
            "name": "NYC Yellow Taxi Trip Data",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "elemento/nyc-yellow-taxi-trip-data",
            "folder": "nyc_taxi",
            "description": "NYC Yellow Taxi Trip Data - Kaggle è³‡æ–™é›†"
        },
        {
            "module": "æ¨¡çµ„ä¸ƒ",
            "topic": "ç‰¹å¾µé¸æ“‡èˆ‡é™ç¶­",
            "name": "Breast Cancer Wisconsin",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "uciml/breast-cancer-wisconsin-data",
            "folder": "breast_cancer"
        },
        {
            "module": "æ¨¡çµ„å…«",
            "topic": "æ™‚é–“åºåˆ—ç‰¹å¾µå·¥ç¨‹",
            "name": "Electric Power Consumption",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "uciml/electric-power-consumption-data-set",
            "folder": "power_consumption"
        },
        {
            "module": "æ¨¡çµ„ä¹",
            "topic": "å¤šæ¨¡æ…‹ç‰¹å¾µå·¥ç¨‹",
            "name": "IMDB 50K Movie Reviews",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "lakshmi25npathi/imdb-dataset-of-50k-movie-reviews",
            "folder": "imdb_reviews"
        },
        {
            "module": "æ¨¡çµ„ä¹",
            "topic": "å¤šæ¨¡æ…‹ç‰¹å¾µå·¥ç¨‹",
            "name": "Dogs vs Cats",
            "type": "competition",
            "method": "kagglehub_only",
            "competition_id": "dogs-vs-cats",
            "folder": "dogs_vs_cats"
        },
        {
            "module": "æ¨¡çµ„ä¹",
            "topic": "å¤šæ¨¡æ…‹ç‰¹å¾µå·¥ç¨‹",
            "name": "UrbanSound8K",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "rupakroy/urban-sound-8k",
            "folder": "urban_sound"
        },
        {
            "module": "æ¨¡çµ„å",
            "topic": "è³‡æ–™æ¢å‹˜æ‡‰ç”¨",
            "name": "Instacart Market Basket Analysis",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "psparks/instacart-market-basket-analysis",
            "folder": "instacart"
        },
        {
            "module": "æ¨¡çµ„å",
            "topic": "è³‡æ–™æ¢å‹˜æ‡‰ç”¨",
            "name": "Mall Customers",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "vjchoudhary7/customer-segmentation-tutorial-in-python",
            "folder": "mall_customers"
        },
        {
            "module": "æ¨¡çµ„å",
            "topic": "è³‡æ–™æ¢å‹˜æ‡‰ç”¨",
            "name": "Telco Customer Churn",
            "type": "dataset",
            "method": "kaggle_cli",
            "dataset_id": "blastchar/telco-customer-churn",
            "folder": "telco_churn"
        }
    ]
    return datasets

# åŸç”Ÿ Kaggle CLI ä¸‹è¼‰æ–¹æ³•
def download_with_kaggle_cli(dataset, target_folder):
    """ä½¿ç”¨åŸç”Ÿ Kaggle CLI ä¸‹è¼‰è³‡æ–™é›†ï¼Œä¸¦è‡ªå‹•è§£å£“ç¸®"""
    try:
        is_competition = dataset.get("type") == "competition"
        
        if is_competition:
            # ç«¶è³½ä¸‹è¼‰
            entity_id = dataset["competition_id"]
            cmd = ['kaggle', 'competitions', 'download', '-c', entity_id, '--path', target_folder]
        else:
            # è³‡æ–™é›†ä¸‹è¼‰
            entity_id = dataset["dataset_id"]
            cmd = ['kaggle', 'datasets', 'download', entity_id, '--path', target_folder, '--unzip']
        
        print(f"   ğŸ“‹ åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True)
        
        # Manually decode stdout and stderr with error handling
        stdout_decoded = result.stdout.decode('utf-8', errors='replace')
        stderr_decoded = result.stderr.decode('utf-8', errors='replace')

        if result.returncode == 0:
            print(f"âœ… åŸç”Ÿ CLI ä¸‹è¼‰æˆåŠŸï¼")

            # å¦‚æœæ˜¯ç«¶è³½ï¼Œå‰‡æ‰‹å‹•è§£å£“ç¸®
            if is_competition:
                # å°‹æ‰¾ä¸‹è¼‰çš„ zip æª”æ¡ˆ
                zip_filename = f"{entity_id}.zip"
                zip_filepath = os.path.join(target_folder, zip_filename)

                if os.path.exists(zip_filepath):
                    print(f"   ğŸ”„ æ­£åœ¨è§£å£“ç¸®æª”æ¡ˆ: {zip_filename}...")
                    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:
                        zip_ref.extractall(target_folder)
                    print(f"   âœ… è§£å£“ç¸®å®Œæˆã€‚")
                    os.remove(zip_filepath) # åˆªé™¤ zip æª”æ¡ˆ
                    print(f"   ğŸ—‘ï¸  å·²åˆªé™¤åŸå§‹ Zip æª”æ¡ˆã€‚")
                else:
                    # æœ‰äº›ç«¶è³½å¯èƒ½ä¸æœƒæ˜¯æ¨™æº–çš„ zip åç¨±, æ¯”å¦‚ titanic
                    for file in os.listdir(target_folder):
                        if file.endswith('.zip'):
                            zip_filepath = os.path.join(target_folder, file)
                            print(f"   ğŸ”„ æ‰¾åˆ°ä¸¦è§£å£“ç¸®æª”æ¡ˆ: {file}...")
                            with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:
                                zip_ref.extractall(target_folder)
                            os.remove(zip_filepath)
                            print(f"   âœ… è§£å£“ç¸®å®Œæˆä¸¦å·²åˆªé™¤ Zip æª”æ¡ˆã€‚")
                            break

            files = [f for f in os.listdir(target_folder) if not f.endswith('.zip')]
            print(f"ğŸ“ ç›®éŒ„ä¸­çš„æª”æ¡ˆ: {files}")
            return True
        else:
            # æª¢æŸ¥ stderr å’Œ stdout ä¸­çš„éŒ¯èª¤ä¿¡æ¯
            error_msg = stderr_decoded.strip() if stderr_decoded else ""
            output_msg = stdout_decoded.strip() if stdout_decoded else ""
            combined_msg = f"{error_msg} {output_msg}".strip()
            
            if not combined_msg:
                combined_msg = "æœªçŸ¥éŒ¯èª¤"
            
            if "401" in combined_msg or "Unauthorized" in combined_msg:
                print(f"âŒ CLI ä¸‹è¼‰å¤±æ•— (401 Unauthorized): è«‹å…ˆåˆ° Kaggle ç¶²ç«™æ¥å—è©²ç«¶è³½/è³‡æ–™é›†çš„ä½¿ç”¨æ¢æ¬¾ã€‚")
                if dataset.get('type') == "competition":
                    print(f"ğŸ”— ç«¶è³½æ¢æ¬¾é€£çµ: https://www.kaggle.com/c/{dataset.get('competition_id', 'unknown')}")
                else:
                    print(f"ğŸ”— è³‡æ–™é›†é€£çµ: https://www.kaggle.com/datasets/{dataset.get('dataset_id', 'unknown')}")
            elif "403" in combined_msg or "Forbidden" in combined_msg:
                print(f"âŒ CLI ä¸‹è¼‰å¤±æ•— (403 Forbidden): è«‹å…ˆåˆ° Kaggle ç¶²ç«™æ¥å—è©²ç«¶è³½/è³‡æ–™é›†çš„ä½¿ç”¨æ¢æ¬¾ã€‚")
            elif "404" in combined_msg or "Not Found" in combined_msg:
                print(f"âŒ CLI ä¸‹è¼‰å¤±æ•— (404 Not Found): æ‰¾ä¸åˆ°è©²è³‡æ–™é›†ï¼Œè«‹æª¢æŸ¥ ID æ˜¯å¦æ­£ç¢ºã€‚")
            else:
                print(f"âŒ åŸç”Ÿ CLI ä¸‹è¼‰å¤±æ•—: {combined_msg}")
            return False
            
    except Exception as e:
        print(f"âŒ åŸç”Ÿ CLI ä¸‹è¼‰ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {str(e)}")
        return False

# KaggleHub ä¸‹è¼‰æ–¹æ³•ï¼ˆæ”¹é€²ç‰ˆ - åŸºæ–¼ simple_download.py çš„é©—è­‰æ–¹æ³•ï¼‰
def download_with_kagglehub(dataset, target_folder):
    """ä½¿ç”¨ KaggleHub ä¸‹è¼‰è³‡æ–™é›†åˆ°æŒ‡å®šè³‡æ–™å¤¾"""
    if not KAGGLEHUB_AVAILABLE:
        print("âŒ KaggleHub æœªå®‰è£")
        return False
    
    try:
        from pathlib import Path
        
        is_competition = dataset.get("type") == "competition"
        
        if is_competition:
            # ç«¶è³½ä¸‹è¼‰
            entity_id = dataset["competition_id"]
            print(f"   ğŸ“‹ ä½¿ç”¨ KaggleHub ä¸‹è¼‰ç«¶è³½: {entity_id}")
            cache_path = kagglehub.competition_download(entity_id)
        else:
            # è³‡æ–™é›†ä¸‹è¼‰
            entity_id = dataset["dataset_id"]
            print(f"   ğŸ“‹ ä½¿ç”¨ KaggleHub ä¸‹è¼‰è³‡æ–™é›†: {entity_id}")
            cache_path = kagglehub.dataset_download(entity_id)
        
        print(f"âœ… KaggleHub ä¸‹è¼‰æˆåŠŸï¼Œç·©å­˜è·¯å¾‘: {cache_path}")
        
        # å‰µå»ºç›®æ¨™è³‡æ–™å¤¾
        target_path = Path(target_folder)
        target_path.mkdir(parents=True, exist_ok=True)
        
        # è¤‡è£½æª”æ¡ˆåˆ°ç›®æ¨™è³‡æ–™å¤¾
        print(f"   ğŸ“ è¤‡è£½æª”æ¡ˆåˆ°ç›®æ¨™ç›®éŒ„: {target_folder}")
        
        # å¦‚æœç›®æ¨™è³‡æ–™å¤¾å·²å­˜åœ¨ä¸”ä¸ç‚ºç©ºï¼Œå…ˆæ¸…ç©º
        if target_path.exists() and any(target_path.iterdir()):
            import shutil
            shutil.rmtree(target_path)
            target_path.mkdir(parents=True, exist_ok=True)
        
        # è¤‡è£½æ‰€æœ‰æª”æ¡ˆ
        cache_path_obj = Path(cache_path)
        if cache_path_obj.is_file():
            # å¦‚æœæ˜¯å–®å€‹æª”æ¡ˆ
            import shutil
            shutil.copy2(cache_path, target_path / cache_path_obj.name)
        else:
            # å¦‚æœæ˜¯è³‡æ–™å¤¾ï¼Œè¤‡è£½æ‰€æœ‰å…§å®¹
            import shutil
            for item in cache_path_obj.iterdir():
                if item.is_file():
                    shutil.copy2(item, target_path / item.name)
                elif item.is_dir():
                    shutil.copytree(item, target_path / item.name)
        
        print(f"   âœ… è¤‡è£½å®Œæˆ")
        
        # é¡¯ç¤ºä¸‹è¼‰çš„æª”æ¡ˆ
        files = list(target_path.glob('*'))
        print(f"   ğŸ“„ è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆ: {[f.name for f in files]}")
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "permission" in error_msg.lower():
            print(f"âŒ KaggleHub ä¸‹è¼‰å¤±æ•— (401 Unauthorized): è«‹å…ˆåˆ° Kaggle ç¶²ç«™æ¥å—è©²ç«¶è³½/è³‡æ–™é›†çš„ä½¿ç”¨æ¢æ¬¾ã€‚")
            if is_competition:
                print(f"ğŸ”— ç«¶è³½æ¢æ¬¾é€£çµ: https://www.kaggle.com/c/{entity_id}")
            else:
                print(f"ğŸ”— è³‡æ–™é›†é€£çµ: https://www.kaggle.com/datasets/{entity_id}")
        else:
            print(f"âŒ KaggleHub ä¸‹è¼‰å¤±æ•—: {error_msg}")
        return False

# å…¨åŸŸå°å…¥ kagglehubï¼Œé¿å…é‡è¤‡å°å…¥
try:
    import kagglehub
    KAGGLEHUB_AVAILABLE = True
except ImportError:
    kagglehub = None
    KAGGLEHUB_AVAILABLE = False

# ä¸‹è¼‰è³‡æ–™é›†
def download_dataset(dataset, base_dir):
    """ä¸‹è¼‰å–®å€‹è³‡æ–™é›†åˆ°æŒ‡å®šç›®éŒ„ï¼Œæ ¹æ“šé è¨­æ–¹æ³•"""
    from tqdm import tqdm
    
    target_folder = os.path.join(base_dir, "raw", dataset["folder"])
    os.makedirs(target_folder, exist_ok=True)
    
    method = dataset.get("method", "kaggle_cli")
    
    # --- Display Info ---
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ {dataset['name']}")
    print(f"ğŸ“‚ æ¨¡çµ„: {dataset.get('module', 'N/A')} - {dataset.get('topic', 'N/A')}")
    
    method_map = {
        'kaggle_cli': 'ğŸ’» Kaggle CLI', 
        'direct': 'ğŸŒ ç›´æ¥ä¸‹è¼‰',
        'kagglehub_only': 'ğŸ¤— KaggleHub'
    }
    print(f"ğŸ”§ ä½¿ç”¨æ–¹æ³•: {method_map.get(method, 'æœªçŸ¥')}")
    print(f"ğŸ“ ç›®æ¨™è³‡æ–™å¤¾: {target_folder}")
    
    success = False

    # --- Direct Download Method ---
    if method == 'direct':
        with tqdm(total=100, desc="ğŸŒ ç›´æ¥ä¸‹è¼‰", bar_format='{l_bar}{bar}| {percentage:3.0f}%') as pbar:
            try:
                import requests
                url = dataset['direct_url']
                pbar.set_description(f"â¬‡ï¸ ä¸‹è¼‰ {os.path.basename(url)}...")
                
                response = requests.get(url, stream=True)
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                
                local_file = os.path.join(target_folder, os.path.basename(url))
                with open(local_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            pbar.n = int(progress)
                            pbar.refresh()
                
                pbar.n = 100
                pbar.set_description("âœ… ä¸‹è¼‰å®Œæˆ")
                print(f"\nâœ… æˆåŠŸä¸‹è¼‰ {dataset['name']} è³‡æ–™é›†ï¼")
                print(f"ğŸ“ è³‡æ–™é›†è·¯å¾‘: {local_file}")
                success = True
            except Exception as e:
                pbar.n = 100
                pbar.set_description("âŒ ç›´æ¥ä¸‹è¼‰å¤±æ•—")
                print(f"\nâŒ ç›´æ¥ä¸‹è¼‰å¤±æ•—: {str(e)}")
                success = False

        # Try backup URLs if primary failed
        if not success and "backup_urls" in dataset:
            print("\nğŸ”„ ä¸»è¦ä¸‹è¼‰å¤±æ•—ï¼Œå˜—è©¦å‚™ç”¨ URL...")
            for backup_url in dataset["backup_urls"]:
                # å»ºç«‹ä¸€å€‹æ–°çš„ dataset dict ä¾†éæ­¸èª¿ç”¨
                backup_dataset_info = {
                    "name": f"{dataset['name']} (å‚™ç”¨)",
                    "method": "direct",
                    "direct_url": backup_url,
                    "folder": dataset['folder'],
                    "module": dataset.get('module'),
                    "topic": dataset.get('topic')
                }
                if download_dataset(backup_dataset_info, base_dir):
                    success = True
                    break

    # --- Kaggle CLI Method ---
    elif method == 'kaggle_cli':
        with tqdm(total=100, desc="ğŸ’» Kaggle CLI", bar_format='{l_bar}{bar}| {percentage:3.0f}%') as pbar:
            pbar.set_description("ğŸ”§ æº–å‚™ CLI å‘½ä»¤..."); pbar.update(20)
            if download_with_kaggle_cli(dataset, target_folder):
                pbar.set_description("âœ… CLI ä¸‹è¼‰å®Œæˆ"); pbar.update(80)
                success = True
            else:
                pbar.set_description("ğŸ”„ å˜—è©¦ KaggleHub å‚™ç”¨æ–¹æ³•"); pbar.update(40)
                if KAGGLEHUB_AVAILABLE and download_with_kagglehub(dataset, target_folder):
                    pbar.set_description("âœ… KaggleHub ä¸‹è¼‰å®Œæˆ"); pbar.update(40)
                    success = True
                else:
                    pbar.set_description("âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—"); pbar.update(20)
                    success = False
    
    # --- KaggleHub Only Method ---
    elif method == 'kagglehub_only':
        with tqdm(total=100, desc="ğŸ¤— KaggleHub", bar_format='{l_bar}{bar}| {percentage:3.0f}%') as pbar:
            pbar.set_description("ğŸ”§ æº–å‚™ KaggleHub..."); pbar.update(20)
            if download_with_kagglehub(dataset, target_folder):
                pbar.set_description("âœ… KaggleHub ä¸‹è¼‰å®Œæˆ"); pbar.update(80)
                success = True
            else:
                pbar.set_description("âŒ KaggleHub ä¸‹è¼‰å¤±æ•—"); pbar.update(80)
                success = False
    
    else:
        print(f"\nâŒ æœªçŸ¥çš„ä¸‹è¼‰æ–¹æ³•: {method}")
        success = False

    if not success:
        print(f"\nâŒ {dataset['name']} ä¸‹è¼‰å¤±æ•—ã€‚")
        print("ğŸ’¡ å»ºè­°æª¢æŸ¥:")
        print("   â€¢ ç¶²è·¯é€£ç·šæ˜¯å¦æ­£å¸¸")
        if method == 'kaggle_cli':
            print("   â€¢ Kaggle API æ†‘è­‰æ˜¯å¦æ­£ç¢º")
            print("   â€¢ æ˜¯å¦å·²åœ¨ Kaggle ç¶²ç«™ä¸Šæ‰‹å‹•æ¥å—ç«¶è³½/è³‡æ–™é›†ä½¿ç”¨æ¢æ¬¾")
        if dataset.get('type') == "competition":
             print(f"   â€¢ æ‰‹å‹•æ¥å—æ¢æ¬¾: https://www.kaggle.com/c/{dataset['competition_id']}")

    return success


def validate_choice(choice, max_value, option_name="é¸é …"):
    """é©—è­‰ç”¨æˆ¶è¼¸å…¥çš„é¸æ“‡æ˜¯å¦æœ‰æ•ˆ"""
    if choice.isdigit() and 1 <= int(choice) <= max_value:
        return True
    print(f"âŒ ç„¡æ•ˆçš„{option_name}ï¼Œè«‹è¼¸å…¥ 1-{max_value} ä¹‹é–“çš„æ•¸å­—")
    return False


# ä¸»å‡½æ•¸
def main():
    """ä¸»å‡½æ•¸ï¼šæª¢æŸ¥ç’°å¢ƒã€ä¸‹è¼‰è³‡æ–™é›†"""
    print("=" * 60)
    print("è³‡æ–™æ¢å‹˜èª²ç¨‹è³‡æ–™é›†ä¸‹è¼‰å·¥å…·")
    print("=" * 60)
    
    # æª¢æŸ¥ä¸¦å®‰è£å¿…è¦çš„å¥—ä»¶
    check_and_install_packages()
    
    # æª¢æŸ¥ Kaggle API
    check_kaggle_api()
    
    # è¨­ç½®è³‡æ–™ç›®éŒ„
    base_dir = os.path.join(os.getcwd(), "datasets")
    raw_dir = os.path.join(base_dir, "raw")
    processed_dir = os.path.join(base_dir, "processed")
    
    # å‰µå»ºå¿…è¦çš„ç›®éŒ„
    os.makedirs(raw_dir, exist_ok=True)
    os.makedirs(processed_dir, exist_ok=True)
    
    # ç²å–è³‡æ–™é›†è³‡è¨Š
    datasets = get_datasets_info()
    
    # é¡¯ç¤ºå°‡è¦ä¸‹è¼‰çš„è³‡æ–™é›†
    print(f"\nğŸ“‹ å¯ä¸‹è¼‰çš„è³‡æ–™é›†åˆ—è¡¨ (å…± {len(datasets)} å€‹):")
    print("=" * 80)
    
    for i, dataset in enumerate(datasets, 1):
        method = dataset.get("method", "kaggle_cli")
        method_map = {
            'kaggle_cli': '(CLI+Hub)', 
            'direct': '(Direct)', 
            'kagglehub_only': '(Hub Only)'
        }
        method_tag = method_map.get(method, '')

        if method == "direct":
            dataset_type_icon = "ğŸŒ"
            cmd_info = f"ç›´æ¥ä¸‹è¼‰: {dataset['direct_url']}"
        elif method == "kagglehub_only":
            if dataset["type"] == "competition":
                dataset_type_icon = "ğŸ¤—"
                cmd_info = f"kagglehub.competition_download('{dataset['competition_id']}')"
            else:  # dataset
                dataset_type_icon = "ğŸ¤—"
                cmd_info = f"kagglehub.dataset_download('{dataset['dataset_id']}')"
        else:  # kaggle_cli
            if dataset["type"] == "competition":
                dataset_type_icon = "ğŸ†"
                cmd_info = f"kaggle competitions download -c {dataset['competition_id']}"
            else:  # dataset
                dataset_type_icon = "ğŸ“Š"
                cmd_info = f"kaggle datasets download {dataset['dataset_id']}"
        
        print(f"{i:2d}. {dataset_type_icon} {method_tag} {dataset['name']}")
        print(f"    ğŸ“‚ æ¨¡çµ„: {dataset['module']} - {dataset['topic']}")
        print(f"    ğŸ’» æŒ‡ä»¤: {cmd_info}")
        print()
    
    print("ğŸ“Œ åœ–æ¨™èˆ‡æ¨™ç±¤èªªæ˜:")
    print("   ğŸ† = Kaggle ç«¶è³½(CLI), ğŸ“Š = Kaggle è³‡æ–™é›†(CLI), ğŸŒ = ç›´æ¥ä¸‹è¼‰, ğŸ¤— = KaggleHub")
    print("   (CLI+Hub) = Kaggle CLI + KaggleHub å‚™ç”¨, (Direct) = ç›´æ¥ HTTP ä¸‹è¼‰, (Hub Only) = åƒ… KaggleHub")
    print("=" * 80)
    
    # æä¾›é¸é …
    print("\nâš™ï¸  è«‹é¸æ“‡ä¸‹è¼‰é¸é …:")
    print("1. ğŸ“¦ ä¸‹è¼‰æ‰€æœ‰è³‡æ–™é›†ï¼ˆæ™ºèƒ½ä¸‹è¼‰ï¼‰")
    print("2. ğŸ¯ ä¸‹è¼‰ç‰¹å®šæ¨¡çµ„çš„è³‡æ–™é›†ï¼ˆæ™ºèƒ½ä¸‹è¼‰ï¼‰")
    print("3. ğŸ” ä¸‹è¼‰å–®ä¸€è³‡æ–™é›†ï¼ˆæ™ºèƒ½ä¸‹è¼‰ï¼‰")
    print("0. âŒ å–æ¶ˆæ“ä½œ")
    print()
    
    choice = input("\nè«‹è¼¸å…¥é¸é … (0-3): ").strip()
    
    if choice == '1':
        # ä¸‹è¼‰æ‰€æœ‰è³‡æ–™é›†
        from tqdm import tqdm
        
        print(f"\nğŸš€ é–‹å§‹ä¸‹è¼‰æ‰€æœ‰ {len(datasets)} å€‹è³‡æ–™é›†...")
        success_count = 0
        
        with tqdm(total=len(datasets), desc="ğŸ“¦ ç¸½é«”é€²åº¦", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} å€‹è³‡æ–™é›†') as total_pbar:
            for i, dataset in enumerate(datasets, 1):
                total_pbar.set_description(f"ğŸ“¦ è™•ç† {i}/{len(datasets)}: {dataset['name']}")
                
                if download_dataset(dataset, base_dir):
                    success_count += 1
                    total_pbar.set_postfix({'æˆåŠŸ': success_count, 'å¤±æ•—': i - success_count})
                
                total_pbar.update(1)
                time.sleep(1)  # é¿å… API è«‹æ±‚éæ–¼é »ç¹
        
        print(f"\nğŸ‰ ä¸‹è¼‰å®Œæˆï¼æˆåŠŸä¸‹è¼‰ {success_count}/{len(datasets)} å€‹è³‡æ–™é›†ã€‚")
        print(f"ğŸ“ è³‡æ–™é›†å·²ä¿å­˜åœ¨: {raw_dir}")
        
    elif choice == '2':
        # é¡¯ç¤ºæ¨¡çµ„åˆ—è¡¨
        modules = sorted(list(set([d['module'] for d in datasets])))
        print("\nå¯é¸æ¨¡çµ„:")
        for i, module in enumerate(modules, 1):
            print(f"{i}. {module}")
        
        module_choice = input("\nè«‹é¸æ“‡æ¨¡çµ„ç·¨è™Ÿ: ").strip()
        if validate_choice(module_choice, len(modules), "æ¨¡çµ„ç·¨è™Ÿ"):
            selected_module = modules[int(module_choice) - 1]
            module_datasets = [d for d in datasets if d['module'] == selected_module]
            
            print(f"\nå°‡ä¸‹è¼‰ {selected_module} çš„ä»¥ä¸‹è³‡æ–™é›†:")
            for i, dataset in enumerate(module_datasets, 1):
                print(f"{i}. {dataset['name']}")
            
            confirm = input("\nç¢ºèªä¸‹è¼‰? (y/n): ").strip().lower()
            if confirm == 'y':
                from tqdm import tqdm
                
                print(f"\nğŸš€ é–‹å§‹ä¸‹è¼‰ {selected_module} çš„ {len(module_datasets)} å€‹è³‡æ–™é›†...")
                success_count = 0
                
                with tqdm(total=len(module_datasets), desc="ğŸ“¦ æ¨¡çµ„é€²åº¦", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} å€‹è³‡æ–™é›†') as module_pbar:
                    for i, dataset in enumerate(module_datasets, 1):
                        module_pbar.set_description(f"ğŸ“¦ è™•ç† {i}/{len(module_datasets)}: {dataset['name']}")
                        
                        if download_dataset(dataset, base_dir):
                            success_count += 1
                            module_pbar.set_postfix({'æˆåŠŸ': success_count, 'å¤±æ•—': i - success_count})
                        
                        module_pbar.update(1)
                        time.sleep(1)
                
                print(f"\nğŸ‰ ä¸‹è¼‰å®Œæˆï¼æˆåŠŸä¸‹è¼‰ {success_count}/{len(module_datasets)} å€‹è³‡æ–™é›†ã€‚")
                print(f"ğŸ“ è³‡æ–™é›†å·²ä¿å­˜åœ¨: {raw_dir}")
            else:
                print("æ“ä½œå·²å–æ¶ˆã€‚")
    
    elif choice == '3':
        # ä¸‹è¼‰å–®ä¸€è³‡æ–™é›†
        dataset_choice = input(f"\nè«‹è¼¸å…¥è³‡æ–™é›†ç·¨è™Ÿ (1-{len(datasets)}): ").strip()
        if validate_choice(dataset_choice, len(datasets), "è³‡æ–™é›†ç·¨è™Ÿ"):
            dataset = datasets[int(dataset_choice) - 1]
            print(f"\nå°‡ä¸‹è¼‰: {dataset['name']} ({dataset['module']}: {dataset['topic']})")
            
            confirm = input("ç¢ºèªä¸‹è¼‰? (y/n): ").strip().lower()
            if confirm == 'y':
                if download_dataset(dataset, base_dir):
                    print(f"\næˆåŠŸä¸‹è¼‰ {dataset['name']} è³‡æ–™é›†ï¼")
                    print(f"è³‡æ–™é›†å·²ä¿å­˜åœ¨: {os.path.join(raw_dir, dataset['folder'])}")
                else:
                    print(f"\nä¸‹è¼‰ {dataset['name']} è³‡æ–™é›†å¤±æ•—ã€‚")
            else:
                print("æ“ä½œå·²å–æ¶ˆã€‚")
    
    else:
        print("æ“ä½œå·²å–æ¶ˆã€‚")

if __name__ == "__main__":
    main()